{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7zyZ-rL5s6Ju",
        "outputId": "382dcc81-e21f-4430-c39f-11067b14705b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#configuraci칩n en google colab de spark y pyspark\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SFcUBpdFs6Jy"
      },
      "outputs": [],
      "source": [
        "#instalar java y spark\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZWgHQAX2s6Jy"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#forma 1 de crear la sesi칩n y el contexto Spark:\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "#forma 2 de crear la sesi칩n y el contexto Spark:\n",
        "#sc = SparkContext.getOrCreate()\n",
        "#spark=SparkSession.builder.appName('nlp').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "o3B8fcsbs6Jz"
      },
      "outputs": [],
      "source": [
        "#myrdd = sc.wholeTextFiles('../datasets/papers_sample_pdf/*.txt')\n",
        "#df = myrdd.toDF(schema=['filename','content'])\n",
        "#df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I4bbzjCis6Jz"
      },
      "outputs": [],
      "source": [
        "df=spark.createDataFrame([(1,'I really liked this movie'),\n",
        "                         (2,'I would recommend this movie to my friends'),\n",
        "                         (3,'movie was alright but acting was horrible'),\n",
        "                         (4,'I am never watching that movie ever again')],\n",
        "                        ['user_id','content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aRkP98Pxs6J0",
        "outputId": "ede3e6bc-4cb5-4307-ca65-c5f0c2286881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: long (nullable = true)\n",
            " |-- content: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2sIojM4ls6J0",
        "outputId": "65812acb-d649-4c3b-bb3c-481cafe5de25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: long (nullable = true)\n",
            " |-- content: string (nullable = true)\n",
            " |-- tokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-------+--------------------+--------------------+\n",
            "|user_id|             content|              tokens|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|I really liked th...|[i, really, liked...|\n",
            "|      2|I would recommend...|[i, would, recomm...|\n",
            "|      3|movie was alright...|[movie, was, alri...|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|\n",
            "+-------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tokenization\n",
        "from pyspark.ml.feature import Tokenizer\n",
        "tokenization=Tokenizer(inputCol='content',outputCol='tokens')\n",
        "tokenized_df=tokenization.transform(df)\n",
        "tokenized_df.printSchema()\n",
        "tokenized_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "15auHBHos6J1",
        "outputId": "4a833bad-5d64-4bcc-bea9-1f0009c69e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------+----------------------------------+\n",
            "|tokens                                             |refined_tokens                    |\n",
            "+---------------------------------------------------+----------------------------------+\n",
            "|[i, really, liked, this, movie]                    |[really, liked, movie]            |\n",
            "|[i, would, recommend, this, movie, to, my, friends]|[recommend, movie, friends]       |\n",
            "|[movie, was, alright, but, acting, was, horrible]  |[movie, alright, acting, horrible]|\n",
            "|[i, am, never, watching, that, movie, ever, again] |[never, watching, movie, ever]    |\n",
            "+---------------------------------------------------+----------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# stopwords removal \n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')\n",
        "refined_df=stopword_removal.transform(tokenized_df)\n",
        "refined_df.select(['tokens','refined_tokens']).show(10,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4Am8lLRRs6J1",
        "outputId": "a8016caf-86cb-4f99-b0d8-f4a5e037b9e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user_id', 'content', 'tokens', 'refined_tokens']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "refined_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "v4B7ttFfs6J1"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SNbuPd0ks6J2"
      },
      "outputs": [],
      "source": [
        "len_udf = udf(lambda s: len(s), IntegerType())\n",
        "\n",
        "refined_count_df = refined_df.withColumn(\"token_count\", len_udf(col('refined_tokens')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MSLl9h4As6J2",
        "outputId": "4dfa61c8-c6cf-46b5-bc0a-30778debe996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+-----------+\n",
            "|user_id|             content|              tokens|      refined_tokens|token_count|\n",
            "+-------+--------------------+--------------------+--------------------+-----------+\n",
            "|      2|I would recommend...|[i, would, recomm...|[recommend, movie...|          3|\n",
            "|      3|movie was alright...|[movie, was, alri...|[movie, alright, ...|          4|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|[never, watching,...|          4|\n",
            "|      1|I really liked th...|[i, really, liked...|[really, liked, m...|          3|\n",
            "+-------+--------------------+--------------------+--------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "refined_count_df.orderBy(rand()).show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vk7WGYP_s6J2",
        "outputId": "f173c901-5465-4fd7-99da-a89c2da8bcaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+---------------------------------+\n",
            "|refined_tokens                    |features                         |\n",
            "+----------------------------------+---------------------------------+\n",
            "|[really, liked, movie]            |(11,[0,2,3],[1.0,1.0,1.0])       |\n",
            "|[recommend, movie, friends]       |(11,[0,6,7],[1.0,1.0,1.0])       |\n",
            "|[movie, alright, acting, horrible]|(11,[0,1,5,10],[1.0,1.0,1.0,1.0])|\n",
            "|[never, watching, movie, ever]    |(11,[0,4,8,9],[1.0,1.0,1.0,1.0]) |\n",
            "+----------------------------------+---------------------------------+\n",
            "\n",
            "['movie', 'recommend', 'ever', 'never', 'really', 'acting', 'horrible', 'liked', 'watching', 'alright', 'friends']\n"
          ]
        }
      ],
      "source": [
        "# Count Vectorizer\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "count_vec=CountVectorizer(inputCol='refined_tokens',outputCol='features')\n",
        "cv_df=count_vec.fit(refined_df).transform(refined_df)\n",
        "cv_df.select(['refined_tokens','features']).show(4,False)\n",
        "bow = count_vec.fit(refined_df).vocabulary\n",
        "print(bow)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "abLECVHds6J3",
        "outputId": "436f9979-fb68-4153-b9b5-99e0ed5c85ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|user_id|             content|              tokens|      refined_tokens|         tf_features|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      1|I really liked th...|[i, really, liked...|[really, liked, m...|(11,[9,10],[2.0,1...|\n",
            "|      2|I would recommend...|[i, would, recomm...|[recommend, movie...|(11,[1,6,9],[1.0,...|\n",
            "|      3|movie was alright...|[movie, was, alri...|[movie, alright, ...|(11,[1,6,9,10],[1...|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|[never, watching,...|(11,[0,7,8,9],[1....|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TF with HashingTF\n",
        "from pyspark.ml.feature import HashingTF\n",
        "# podria utilizar numFeatures como el tama침o del Bag of Words:\n",
        "l = len(bow)\n",
        "hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features',numFeatures=l)\n",
        "#hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features',numFeatures=11)\n",
        "# compare la salida e interprete con y sin numFeatures:\n",
        "#hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features')\n",
        "\n",
        "hashing_df=hashing_vec.transform(refined_df)\n",
        "hashing_df.show(4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "p0TvvIGos6J3",
        "outputId": "c9c30588-97e7-4a44-dddf-d2ab4f125833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------------------+---------------------------------------------------+----------------------------------+---------------------------------+------------------------------------------------------------------------------+\n",
            "|user_id|content                                   |tokens                                             |refined_tokens                    |tf_features                      |tf_idf_features                                                               |\n",
            "+-------+------------------------------------------+---------------------------------------------------+----------------------------------+---------------------------------+------------------------------------------------------------------------------+\n",
            "|1      |I really liked this movie                 |[i, really, liked, this, movie]                    |[really, liked, movie]            |(11,[9,10],[2.0,1.0])            |(11,[9,10],[0.0,0.5108256237659907])                                          |\n",
            "|2      |I would recommend this movie to my friends|[i, would, recommend, this, movie, to, my, friends]|[recommend, movie, friends]       |(11,[1,6,9],[1.0,1.0,1.0])       |(11,[1,6,9],[0.5108256237659907,0.5108256237659907,0.0])                      |\n",
            "|3      |movie was alright but acting was horrible |[movie, was, alright, but, acting, was, horrible]  |[movie, alright, acting, horrible]|(11,[1,6,9,10],[1.0,1.0,1.0,1.0])|(11,[1,6,9,10],[0.5108256237659907,0.5108256237659907,0.0,0.5108256237659907])|\n",
            "|4      |I am never watching that movie ever again |[i, am, never, watching, that, movie, ever, again] |[never, watching, movie, ever]    |(11,[0,7,8,9],[1.0,1.0,1.0,1.0]) |(11,[0,7,8,9],[0.9162907318741551,0.9162907318741551,0.9162907318741551,0.0]) |\n",
            "+-------+------------------------------------------+---------------------------------------------------+----------------------------------+---------------------------------+------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import IDF\n",
        "tf_idf_vec=IDF(inputCol='tf_features',outputCol='tf_idf_features')\n",
        "tf_idf_df=tf_idf_vec.fit(hashing_df).transform(hashing_df)\n",
        "tf_idf_df.show(4,False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}